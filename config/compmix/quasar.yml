name: "quasar"
log_level: "INFO"
dev: False

# Construct pipeline
qu: sr
ers: rers
ha: quasar

# Define source combinations
source_combinations:
  [
    ["kb"],
    ["text"],
    ["table"],
    ["info"],
    ["kb", "text"],
    ["kb", "table"],
    ["kb", "info"],
    ["text", "table"],
    ["text", "info"],
    ["table", "info"],
    ["kb", "text", "table", "info"]
  ]

#################################################################
#  General file paths
#################################################################
path_to_stopwords: "_data/stopwords.txt"
path_to_labels: "_data/labels.pickle"
path_to_types: "_data/types.pickle"
path_to_wikipedia_mappings: "_data/wikipedia_mappings.pickle"
path_to_wikidata_mappings: "_data/wikidata_mappings.pickle"

#################################################################
#  Benchmark specific settings
#################################################################
benchmark: "compmix"
benchmark_path: "_benchmarks/compmix"

train_input_path: "train_set.json"
dev_input_path: "dev_set.json"
test_input_path: "test_set.json"

path_to_annotated_train: "_intermediate_representations/compmix/annotated_train.json"
path_to_annotated_dev: "_intermediate_representations/compmix/annotated_dev.json"
path_to_intermediate_results: "_intermediate_representations/compmix"

#################################################################
#  Parameters - CLOCQ
#################################################################
clocq_params:
  h_match: 0.4
  h_rel: 0.2
  h_conn: 0.3
  h_coh: 0.1
  d: 20
  k: 10
  p_setting: 1000 # setting for search_space function
  bm25_limit: False
clocq_p: 1000 #  setting for neighborhood function(s) 
clocq_use_api: True # using CLOCQClientInterface
clocq_host: "https://clocq.mpi-inf.mpg.de/api" # host for client
clocq_port: "443" # port for client

#################################################################
#  Parameters - Silver annotation
#################################################################
# general
ds_sources: ["kb"]
ds_prune_noisy_qa_pairs: False

# annotation - SR
sr_relation_shared_active: False
sr_remove_stopwords: False

# OPTIONAL: annotation - turn relevance 
tr_transitive_relevances: False
tr_extract_dataset: False

#################################################################
#  Parameters - QU
#################################################################
sr_architecture: BART
sr_model_path: "_data/compmix/quasar/sr_model.bin"
sr_max_input_length: 512

history_separator: " ||| "
sr_delimiter: "||"

sr_avoid_hallucination: True
sr_k: 10

# training parameters
sr_num_train_epochs: 5
sr_per_device_train_batch_size: 10
sr_per_device_eval_batch_size: 10
sr_warmup_steps: 500
sr_weight_decay: 0.01

# generation parameters
sr_no_repeat_ngram_size: 2
sr_num_beams: 20
sr_early_stopping: True
sr_max_output_length: 30

#################################################################
#  Parameters - ERS
#################################################################  
# cache path
ers_use_cache: True
ers_cache: "_data/compmix/quasar/er_cache.pickle"
ers_wikipedia_dump: "_data/compmix/wikipedia_dump.pickle"
ers_wikipedia_to_wikidata_links_cache: "_data/compmix/cache_wikipedia_to_wikidata_links.pickle"
ers_on_the_fly: True

# evidence retrieval
evr_min_evidence_length: 3
evr_max_evidence_length: 200
evr_max_entities: 10 # max entities per evidence

# evidence scoring
evs_max_evidences: 1000

#################################################################
#  Parameters - Re-ranking
#################################################################
# gnn
gnn_model: heterogeneous_gnn
gnn_num_layers: 3
gnn_answering: multitask_bilinear
gnn_encoder_linear: False
gnn_enc_sr_max_input: 30
gnn_enc_ev_max_input: 80
gnn_enc_ent_max_input: 60
gnn_max_output_evidences: 5

# dataloader
gnn_shuffle_evidences: True # shuffle evidences (no order retained)
gnn_mask_question_entities: False # avoid predicting question entities as answers

# training params
gnn_train_max_pos_evidences: 10
gnn_train_batch_size: 1
gnn_epochs: 5
gnn_learning_rate: 0.00001
gnn_weight_decay: 0.01
gnn_clipping_max_norm: 1.0
gnn_dropout: 0.0

# training models
gnn_train:
  - gnn_encoder_lm: cross-encoder/ms-marco-MiniLM-L-4-v2
    gnn_encoder: alternating_encoder_cross_SR
    gnn_model_path: "_data/compmix/quasar/gnn/quasar-pruning-minilm_l4.bin"
    gnn_emb_dimension: 384
    gnn_multitask_answer_weight: 0.3
    gnn_multitask_ev_weight: 0.7
    gnn_decisive_metric: mrr_evidences # metric for choosing best model from dev set
    gnn_max_evidences: 100
    gnn_max_entities: 400

  - gnn_encoder_lm: cross-encoder/ms-marco-MiniLM-L-6-v2
    gnn_encoder: full_encoder_cross_SR
    gnn_model_path: "_data/compmix/quasar/gnn/quasar-pruning-minilm_l6.bin"
    gnn_emb_dimension: 384
    gnn_multitask_answer_weight: 0.3
    gnn_multitask_ev_weight: 0.7
    gnn_decisive_metric: mrr_evidences # metric for choosing best model from dev set
    gnn_max_evidences: 100
    gnn_max_entities: 400
gnn_eval_batch_size: 10 # batch size for eval during training

# inference
gnn_subgraph_strategy: aggregate
gnn_inference:
  - gnn_encoder_lm: cross-encoder/ms-marco-MiniLM-L-4-v2
    gnn_encoder: alternating_encoder_cross_SR
    gnn_model_path: "_data/compmix/quasar/gnn/quasar-pruning-minilm_l4.bin"
    gnn_emb_dimension: 384
    gnn_max_evidences: 1000
    gnn_max_entities: 4000
    gnn_max_output_evidences: 100

  - gnn_encoder_lm: cross-encoder/ms-marco-MiniLM-L-6-v2
    gnn_encoder: full_encoder_cross_SR
    gnn_model_path: "_data/compmix/quasar/gnn/quasar-pruning-minilm_l6.bin"
    gnn_emb_dimension: 384
    gnn_max_evidences: 100
    gnn_max_entities: 400
    gnn_max_output_evidences: 30
gnn_inference_batch_size: 10

#################################################################
#  Parameters - HA
#################################################################
# general
ha_max_answers: 50
ha_max_input_length: 1024
ha_max_output_length: 20
ha_max_evidence_tokens: 4000
ha_faithful: False

answering_tokenizer_path: "_data/llama/Meta-Llama-3.1-8B-Instruct"
answering_model_base_path: "_data/llama/Meta-Llama-3.1-8B-Instruct"

answering_train_path: _intermediate_representations/compmix/sr/rers/kb_text_table_info/train_rerank-quasar.jsonl
answering_dev_path: _intermediate_representations/compmix/sr/rers/kb_text_table_info/dev_rerank-quasar.jsonl
answering_test_path: _intermediate_representations/compmix/sr/rers/kb_text_table_info/quasar/test_rerank-quasar.jsonl
answering_test_output_path: _intermediate_representations/compmix/sr/rers/kb_text_table_info/quasar/test_ha-llama.jsonl

answering_model_save_path: "_data/compmix/quasar/llama"
answering_model_inference_path: "_data/compmix/quasar/llama"
answering_model_warmup_ratio: 0.1
answering_model_num_epochs: 2
answering_model_train_batch_size: 1
